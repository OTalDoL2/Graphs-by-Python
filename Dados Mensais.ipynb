{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting pr\n",
      "getting ETo\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 393, longitude: 391, time: 235)\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float32 -33.85 -33.75 -33.65 -33.55 ... 5.15 5.25 5.35\n",
      "  * longitude  (longitude) float32 -73.85 -73.75 -73.65 ... -35.05 -34.95 -34.85\n",
      "  * time       (time) datetime64[ns] 2001-01-31 2001-02-28 ... 2020-07-31\n",
      "Data variables:\n",
      "    ETo        (time, latitude, longitude) float32 dask.array<chunksize=(1, 393, 391), meta=np.ndarray>\n",
      "Attributes:\n",
      "    title:                Brazilian Daily Weather Gridded Data (1961-2020)\n",
      "    institution:          Federal University of Espirito Santo; University of...\n",
      "    institution_id:       UFES; UTEXAS\n",
      "    history:              Created Tue May 31 16:03:02 2022\n",
      "    temporal_resolution:  24-hourly\n",
      "    contact:              alexandre.xavier@ufes.br; careyking@energy.utexas.e...\n",
      "    main_code:            ETo.py\n",
      "    update_information:   https://sites.google.com/site/alexandrecandidoxavie...\n",
      "    main_paper:           Xavier, A.C., Scanlon, B.R., King, C.W. and Alves, ...\n",
      "    Interpolate_method:   Calculated with Brazilian Daily Weather Gridded Data\n",
      "arquivo 1 de um total de 1; nome do arquivo: lat-15.79_lon-47.93.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "### ===== EXTRAÇÃO DE DADOS MENSAIS ===== #\n",
    "\n",
    "# set correct path of the netcdf files\n",
    "path_var = 'C:\\\\Users\\lucas.ramos\\OneDrive\\Desktop\\Base Climatica\\Tipos/'\n",
    "\n",
    "# Posicoes: Colocar em ordem, separando por virgula. Neste exemplo temos dois pontos em que as coordenadas\n",
    "# (lat, lon) sao (-20.6,-44.6) e  (-21.0, -44.1), respectivamente para o primeiro e segundo ponto.\n",
    "# Pode-se colocar quantos pontos quiser, apenas separe por virgula.\n",
    "\n",
    "#Região de Fazendas no Maranhão\n",
    "lat = [-15.78944444]\n",
    "lon = [-47.92583332]\n",
    "\n",
    "# variables names\n",
    "# var_names = ['Rs', 'u2','Tmax', 'Tmin', 'RH', 'pr', 'ETo']\n",
    "var_names = ['pr', 'ETo']\n",
    "\n",
    "# function to read the netcdf files\n",
    "def rawData(var2get_xr, var_name2get):\n",
    "    return var2get_xr[var_name2get].sel(longitude=xr.DataArray(lon, dims='z'),\n",
    "                                          latitude=xr.DataArray(lat, dims='z'),\n",
    "                                          method='nearest').values\n",
    "\n",
    "# getting data from NetCDF files\n",
    "for n, var_name2get in enumerate(var_names):\n",
    "    print(\"getting \" + var_name2get)\n",
    "    if var_name2get in [\"pr\", \"ETo\"]:\n",
    "        var2get_xr = xr.open_mfdataset(path_var + var_name2get + '*.nc').resample(time=\"M\").sum(\"time\")\n",
    "        # var2get_xr[var_name2get].sel(latitude=lat[0], longitude=lon[0], method='nearest').plot()\n",
    "    else:\n",
    "        #var2get_xr = xr.open_mfdataset(path_var + var_name2get + '*.nc').resample(time=\"M\").mean(\"time\")\n",
    "        print('aaaaaaaaa')\n",
    "\n",
    "    if n == 0:\n",
    "        var_ar = rawData(var2get_xr, var_name2get)\n",
    "        n_lines = var_ar.shape[0]\n",
    "        time = var2get_xr.time.values\n",
    "    else:\n",
    "        var_ar = np.c_[var_ar, rawData(var2get_xr, var_name2get)]\n",
    "\n",
    "print(var2get_xr)\n",
    "# saving\n",
    "for n in range(len(lat)):\n",
    "    name_file =  'lat{:.2f}_lon{:.2f}.csv'.format(lat[n], lon[n])\n",
    "    print(f'arquivo {n + 1} de um total de {len(lat)}; nome do arquivo: {name_file}')\n",
    "    if ~np.isnan(var_ar[0, n]):\n",
    "        file = var_ar[:, n::len(lon)]\n",
    "        pd.DataFrame(file, index=time, columns=var_names).to_csv(name_file, float_format='%.1f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d1063306dd2dfa409579677bd8f1fbeb22bfb9a1fae2590d0b03201f536f820"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
